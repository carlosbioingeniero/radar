{ 
  "quadrants" : [
    { "id" : "techniques", "name" : "Techniques" },
    { "id" : "platforms", "name" : "Platforms" },
    { "id" : "language-and-frameworks", "name" : "Language and frameworks" },
    { "id" : "tools", "name" : "Tools" }  
  ],
  "rings" : [
    { "id" : "adopt", "name" : "ADOPT", "color" : "#93c47d" },
    { "id" : "trial", "name" : "TRIAL", "color" : "#93d2c2" },
    { "id" : "assess", "name" : "ASSESS", "color" : "#fbdb84" },
    { "id" : "hold", "name" : "HOLD", "color" : "#efafa9" }    
  ],
  "entries": [
    {
      "quadrant": "tools",
      "description": "[**JaCoCo**](http://https://www.baeldung.com/jacoco) is a free Java code coverage library distributed under the Eclipse Public License.",
      "key": "Jacoco",
      "id": "test",
      "title": "Jacoco",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "One of the challenges of using cloud services is being able to develop and test locally. **[LocalStack](https://github.com/localstack/localstack)** solves this problem for AWS by providing local [test double](https://martinfowler.com/bliki/TestDouble.html) implementations of a wide range of AWS services, including S3, Kinesis, DynamoDB and Lambda. It builds on top of best-of-breed tools such as [Kinesalite](https://github.com/mhart/kinesalite), [dynalite](https://github.com/mhart/dynalite) and [Moto](https://github.com/spulec/moto) and adds isolated processes and error injection functionality. LocalStack is very easy to use, ships with a simple JUnit runner and a JUnit 5 extension and can also run inside a docker container. For many teams, it has become the default for testing services that are deployed on AWS.",
      "key": "LocalStack",
      "id": "test",
      "title": "LocalStack",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "[**Helm**](http://helm.sh) is a package manager for Kubernetes. It comes with a repository of curated Kubernetes applications that are maintained in the official [Charts repository](https://github.com/helm/charts). Helm has two components: a command line utility called Helm and a cluster component called Tiller. Securing a Kubernetes cluster is a wide and nuanced topic, but we highly recommend setting up Tiller in a role-based access control (RBAC) environment. We\\'ve used Helm in a number of client projects and its dependency management, templating and hook mechanism has greatly simplified the application lifecycle management in Kubernetes. However, we recommend proceeding with caution — Helm\\'s YAML templating can be difficult to understand, and Tiller still has some rough edges. Helm 3 is expected to address these issues.",
      "key": "Helm",
      "id": "test",
      "title": "Helm",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "SoapUI is an open-source web service testing application for service-oriented architectures (SOA) and representational state transfers (REST). Its functionality covers web service inspection, invoking, development, simulation and mocking, functional testing, load and compliance testing",
      "key": "SoapUI",
      "id": "SoapUI",
      "title": "SoapUI",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "The Apache JMeter application is open source software, a 100% pure Java application designed to load test functional behavior and measure performance. Apache JMeter may be used to test performance both on static and dynamic resources, Web dynamic applications. It can be used to simulate a heavy load on a server, group of servers, network or object to test its strength or to analyze overall performance under different load types",
      "key": "JMeter",
      "id": "JMeter",
      "title": "JMeter",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**[AVA](https://github.com/avajs/ava)** is a test runner for Node.js. Even though JavaScript is single-threaded, IO in Node.js can happen in parallel because of its asynchronous nature. AVA takes advantage of this and runs your tests concurrently, which is especially beneficial for IO-heavy tests. In addition, test files are run in parallel as separate processes, giving you even better performance and an isolated environment for each test file. AVA is a lightweight option, when compared to full-featured frameworks such as Jest. It is opinionated and forces you to write atomic test cases.",
      "key": "AVA",
      "id": "AVA",
      "title": "AVA",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "**[Terraform](https://www.terraform.io/)**, is rapidly becoming a de facto choice for creating and managing cloud infrastructures by writing declarative definitions. The configuration of the servers instantiated by Terraform is usually left to Puppet, Chef or Ansible. We like Terraform because the syntax of its files is quite readable and because it supports a number of cloud providers while making no attempt to provide an artificial abstraction across those providers. The active community will add support for the latest features from most cloud providers. Following our first, more cautious, mention of Terraform almost two years ago, it has seen continued development and has evolved into a stable product with a good ecosystem that has proven its value in our projects. The issue with state file management can now be sidestepped by using what Terraform calls a \"remote state backend.\" We\\'ve successfully used [AWS S3](https://aws.amazon.com/s3/) for that purpose.",
      "key": "Terraform",
      "id": "Terraform",
      "title": "Terraform",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "Git is a distributed version-control system for tracking changes in source code during software development. It is designed for coordinating work among programmers, but it can be used to track changes in any set of files. Its goals include speed, data integrity, and support for distributed, non-linear workflows",
      "key": "Git",
      "id": "Git",
      "title": "Git",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "Postman is an API(application programming interface) development tool which helps to build, test and modify APIs. It has the ability to make various types of HTTP requests(GET, POST, PUT, PATCH), saving environments for later use, converting the API to code for various languages(like JavaScript, Python).",
      "key": "Postman",
      "id": "Postman",
      "title": "Postman",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "npm (originally short for Node Package Manager) is a package manager for the JavaScript programming language. It is the default package manager for the JavaScript runtime environment Node.js. It consists of a command line client, also called npm, and an online database of public and paid-for private packages, called the npm registry. The registry is accessed via the client, and the available packages can be browsed and searched via the npm website",
      "key": "Npm",
      "id": "Npm",
      "title": "Npm",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "Gradle is an open-source build-automation system that builds upon the concepts of Apache Ant and Apache Maven and introduces a Groovy-based domain-specific language (DSL) instead of the XML form used by Apache Maven for declaring the project configuration",
      "key": "Gradle",
      "id": "Gradle",
      "title": "Gradle",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "**Chaos toolkit** is a tool that orchestrates chaos engineering scenarios, this is achieved through drivers that expose functions that allow access to the system and its capabilities either to inject faults or to know your state. **This tool defined in Bancolombia**",
      "key": "Chaos Toolkit",
      "id": "Chaos Toolkit",
      "title": "Chaos Toolkit",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**Serenity BDD** helps you write cleaner and more maintainable automated acceptance and regression tests faster. Serenity also uses the test results to produce illustrated, narrative reports that document and describe what your application does and how it works. Serenity tells you not only what tests have been executed, but more importantly, what requirements have been tested.",
      "key": "Serenity BDD",
      "id": "Serenity BDD",
      "title": "Serenity BDD",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "Protractor is an end-to-end test framework for Angular and AngularJS applications. Protractor runs tests against your application running in a real browser, interacting with it as a user would",
      "key": "Protractor",
      "id": "Protractor",
      "title": "Protractor",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "**Selenium** is an umbrella project for a range of tools and libraries that enable and support the automation of web browsers.</br>Selenium brings together browser vendors, engineers, and enthusiasts to further an open discussion around automation of the web platform. The project organises an annual conference to teach and nurture the community. \\nAt the core of Selenium is **WebDriver**, an interface to write instruction sets that can be run interchangeably in many browsers",
      "key": "Selenium",
      "id": "Selenium",
      "title": "Selenium",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**Jest** is a delightful JavaScript Testing Framework with a focus on simplicity. It works with projects using: Babel, TypeScript, Node, React, Angular, Vue and more!\\n Jest is a JavaScript testing framework designed to ensure correctness of any JavaScript codebase. It allows you to write tests with an approachable, familiar and feature-rich API that gives you results quickly. \\n Jest is well-documented, requires little configuration and can be extended to match your requirements. Jest makes testing delightful.",
      "key": "Jest",
      "id": "Jest",
      "title": "Jest",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "[AWS CloudFormation](https://aws.amazon.com/cloudformation/) provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. CloudFormation allows you to use programming languages or a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all regions and accounts. This gives you a single source of truth for your AWS resources",
      "key": "CloudFormation",
      "id": "CloudFormation",
      "title": "CloudFormation",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**AWS Cloud Development Kit (AWS CDK)** is a software development framework for defining cloud infrastructure in code and provisioning it through AWS CloudFormation. \\nThe AWS CDK supports TypeScript, JavaScript, Python, Java, and C#/.Net.",
      "key": "AWS CDK",
      "id": "AWS CDK",
      "title": "AWS CDK",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**Node.js** is an open-source, cross-platform, JavaScript runtime environment that executes JavaScript code outside of a browser. Node.js lets developers use JavaScript to write command line tools and for server-side scripting—running scripts server-side to produce dynamic web page content before the page is sent to the user\\'s web browser",
      "key": "NodeJs",
      "id": "NodeJs",
      "title": "NodeJs",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**[TypeScript](https://www.typescriptlang.org/)**, a statically typed language and superset of JavaScript, has become our sensible default. Large-scale projects benefit most from the type safety. Our developers favor its minimal configuration management, well-integrated IDE support and its ability to refactor code safely and gradually adopt types. With its [good repository](https://definitelytyped.org/) of TypeScript-type definitions at hand, we benefit from all the rich JavaScript libraries while gaining type safety.",
      "key": "TypeScript/Javascript",
      "id": "TypeScript/Javascript",
      "title": "TypeScript/Javascript",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**React.js** is a JavaScript library for building user interfaces. It\\'s declarative and Component-based.",
      "key": "React.js",
      "id": "React.js",
      "title": "React.js",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**RxJS** is a library for composing asynchronous and event-based programs by using observable sequences. It provides one core type, the Observable, satellite types (Observer, Schedulers, Subjects) and operators inspired by Array#extras (map, filter, reduce, every, etc) to allow handling asynchronous events as collections.",
      "key": "RxJS",
      "id": "RxJS",
      "title": "RxJS",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**RPG** is a high-level fully procedural programming language used by businesses to create commercial business applications on IBM’s leading minicomputer system, the AS400 or iSeries. RPG has gained wide acceptance and has evolved massively since its inception. Today several ERP’s and mission critical business applications, are written in RPG based on RPG IV, because it is enabled to provide an interactive programming environment to AS400 RPG Programmers.",
      "key": "RPG",
      "id": "RPG",
      "title": "RPG",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**COBOL** is a programming language that is mainly focused on solving a business problem. Full form of COBOL is Common Business-Oriented Language. It is primarily used in company and government business, finance, and administrative systems. This language also used as a solution to many data processing problems.",
      "key": "Cobol",
      "id": "Cobol",
      "title": "Cobol",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Xamarin extends the .NET platform with tools and libraries specifically for building apps on iOS, Android, macOS, and more.",
      "key": "Xamarin",
      "id": "Xamarin",
      "title": "Xamarin",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**Flutter** is Google’s UI toolkit for building beautiful, natively compiled applications for mobile, web, and desktop from a single codebase. It has an Expressive and Flexible UI, it brings Native Performance and it allows a fast development by using a rich set of fully-customizable widgets.",
      "key": "Flutter",
      "id": "Flutter",
      "title": "Flutter",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**AngularJS** lets you extend HTML vocabulary for your application. The resulting environment is extraordinarily expressive, readable, and quick to develop.\\nAngularJS is a toolset for building the framework most suited to your application development. It is fully extensible and works well with other libraries. Every feature can be modified or replaced to suit your unique development workflow and feature needs. Read on to find out how.",
      "key": "AngularJs",
      "id": "AngularJs",
      "title": "AngularJs",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**Angular** is an application design framework and development platform for creating efficient and sophisticated single-page apps. Angular provides one way to build applications and reuse your code and abilities to build apps for any deployment target. For web, mobile web, native mobile and native desktop.",
      "key": "Angular",
      "id": "Angular",
      "title": "Angular",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Java is a general-purpose programming language that is class-based, object-oriented, and designed to have as few implementation dependencies as possible. It is intended to let application developers write once, run anywhere (WORA), meaning that compiled Java code can run on all platforms that support Java without the need for recompilation",
      "key": "Java",
      "id": "Java",
      "title": "Java",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects",
      "key": "Python",
      "id": "Python",
      "title": "Python",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Mockito is a mocking framework for java. It lets you write tests with a clean and simple API. Mockito doesn’t give you hangover because the tests are very readable and they produce clean verification errors",
      "key": "Mockito",
      "id": "Mockito",
      "title": "Mockito",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "PowerMock is a framework that extends other mock libraries such as EasyMock with more powerful capabilities. PowerMock uses a custom classloader and bytecode manipulation to enable mocking of static methods, constructors, final classes and methods, private methods, removal of static initializers and more",
      "key": "PowerMock",
      "id": "PowerMock",
      "title": "PowerMock",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Elixir is an alternative language for the Erlang virtual machine that allows you to write cleaner, more compact code that does a better job of revealing your intentions. You write programs in Elixir and run them normally in BEAM.\\n Elixir targets the Erlang runtime. The result of compiling the Elixir source code is BEAM-compliant bytecode files that can run in a BEAM instance and can normally cooperate with pure Erlang code — you can use Erlang libraries from Elixir and vice versa. There’s nothing you can do in Erlang that can’t be done in Elixir, and usually the Elixir code is as performant as its Erlang counterpart.\\n Elixir provides constructs that make it possible to radically reduce boilerplate and duplication. \\n Elixir solution is usually easier to develop and maintain thanks to some nice syntactic sugar and a uniform tool for creating and packaging systems.",
      "key": "Elixir - Erlang/OTP",
      "id": "Elixir - Erlang/OTP",
      "title": "Elixir - Erlang/OTP",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Super-agent driven library for testing node.js HTTP servers using a fluent API",
      "key": "SuperTest",
      "id": "SuperTest",
      "title": "SuperTest",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "The Spring Framework is an application framework and inversion of control container for the Java platform. The framework\\'s core features can be used by any Java application, but there are extensions for building web applications on top of the Java EE (Enterprise Edition) platform.",
      "key": "Spring Framework",
      "id": "Spring Framework",
      "title": "Spring Framework",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Hibernate ORM (Hibernate in short) is an object-relational mapping tool for the Java programming language. It provides a framework for mapping an object-oriented domain model to a relational database. Hibernate handles object-relational impedance mismatch problems by replacing direct, persistent database accesses with high-level object handling functions.",
      "key": "Hibernate",
      "id": "Hibernate",
      "title": "Hibernate",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Spark Framework is a simple and expressive Java/Kotlin web framework DSL built for rapid development. Sparks intention is to provide an alternative for Kotlin/Java developers that want to develop their web applications as expressive as possible and with minimal boilerplate. With a clear philosophy Spark is designed not only to make you more productive, but also to make your code better under the influence of Spark’s sleek, declarative and expressive syntax.",
      "key": "Spark Framework",
      "id": "Spark Framework",
      "title": "Spark Framework",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Alongside HTML and CSS, JavaScript is one of the core technologies of the World Wide Web. JavaScript enables interactive web pages and is an essential part of web applications.",
      "key": "Reactor",
      "id": "Reactor",
      "title": "Reactor",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "[**Resilience4j**](https://github.com/resilience4j/resilience4j) is a lightweight fault tolerance library inspired by Netflix Hystrix. We like its lightweight and modular structure where we pull in specific modules for specific capabilities such as circuit-breaking, rate-limiting, retry, and bulkhead. While service meshes are taking on some of the fault tolerance capabilities, fault tolerance libraries continue to remain a key component of our systems for more nuanced domain-specific fault tolerance behavior and for non-containerized services. With Hystrix going into [maintenance mode](https://github.com/Netflix/Hystrix/commit/a7df971cbaddd8c5e976b3cc5f14013fe6ad00e6#diff-04c6e90faac2675aa89e2176d2eec7d8), Resilience4j becomes a default choice in the Java ecosystem. It can work with synchronous APIs as well as reactive ones. It also surfaces metrics to [dropwizard metrics](https://metrics.dropwizard.io/4.0.0/), prometheus and others using additional modules.",
      "key": "Resilience4j",
      "id": "Resilience4j",
      "title": "Resilience4j",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "**[WebFlux](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html)** is the Spring Framework implementation of [Reactive Streams](https://www.reactive-streams.org/). We see a rise in reactive programming models across our teams in general and the use of WebFlux in teams who are working in the Spring ecosystem. It\\'s best used in large microservices ecosystems where the high performance of the requests is a major concern. It allows overlapping request processing asynchronously without the complications of using multiple threads. WebFlux uses [Reactor](https://github.com/reactor/reactor) as its reactive library but it is interoperable with other reactive libraries via Reactive Streams. It uses [Netty](https://netty.io/) as its underlying high-performance communications engine. Although we encourage using Reactive Streams, adopting this programming model requires a significant shift in thinking.",
      "key": "WebFlux",
      "id": "WebFlux",
      "title": "WebFlux",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**React Native** is an open source platform for developing native mobile applications; it was developed largely by a team at Facebook. The cool part of working with React Native is that your program uses standard web technologies like JavaScript (JSX), CSS, and HTML, yet your application is fully native. In other words, your application is fast and smooth, and it is equivalent to any native application built using traditional iOS technologies like Objective-C and Swift. However, React Native does not compromise in terms of performance and overall experience, like popular hybrid frameworks that use web technologies to build iOS apps.",
      "key": "React Native",
      "id": "React Native",
      "title": "React Native",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon RDS is a distributed relational database service by Amazon Web Services (AWS). SQL Server is a relational database management system developed by Microsoft. Amazon RDS for SQL Server makes it easy to set up, operate, and scale SQL Server deployments in the cloud. With Amazon RDS, you can deploy multiple editions of SQL Server (2012, 2014, 2016, 2017 and 2019) including Express, Web, Standard and Enterprise, in minutes with cost-efficient and re-sizable compute capacity. Amazon RDS frees you up to focus on application development by managing time-consuming database administration tasks including provisioning, backups, software patching, monitoring, and hardware scaling",
      "key": "RDS - SQLServer",
      "id": "RDS - SQLServer",
      "title": "RDS - SQLServer",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon RDS for Oracle is a fully managed commercial database that makes it easy to set up, operate, and scale Oracle deployments in the cloud. Amazon RDS frees you up to focus on innovation and application development by managing time-consuming database administration tasks including provisioning, backups, software patching, monitoring, and hardware scaling. You can run Amazon RDS for Oracle under two different licensing models � �License Included� and �Bring-Your-Own-License (BYOL)�. In the \"License Included\" service model, you do not need separately purchased Oracle licenses; the Oracle Database software has been licensed by AWS.",
      "key": "RDS - Oracle",
      "id": "RDS - Oracle",
      "title": "RDS - Oracle",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "With Amazon RDS, you can deploy scalable MySQL servers in minutes with cost-efficient and resizable hardware capacity. Amazon RDS for MySQL frees you up to focus on application development by managing time-consuming database administration tasks including backups, software patching, monitoring, scaling and replication. Amazon RDS supports MySQL Community Edition versions 5.6, 5.7, and 8.0 which means that the code, applications, and tools you already use today can be used with Amazon RDS",
      "key": "RDS - MySQL",
      "id": "RDS - MySQL",
      "title": "RDS - MySQL",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "PostgreSQL has become the preferred open source relational database for many enterprise developers and start-ups, powering leading business and mobile applications. Amazon RDS makes it easy to set up, operate, and scale PostgreSQL deployments in the cloud. With Amazon RDS, you can deploy scalable PostgreSQL deployments in minutes with cost-efficient and resizable hardware capacity. Amazon RDS manages complex and time-consuming administrative tasks such as PostgreSQL software installation and upgrades; storage management; replication for high availability and read throughput; and backups for disaster recovery.",
      "key": "RDS - Postgres",
      "id": "RDS - Postgres",
      "title": "RDS - Postgres",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**Amazon Aurora** is a MySQL and PostgreSQL-compatible relational database built for the cloud, that combines the performance and availability of traditional enterprise databases with the simplicity and cost-effectiveness of open source databases.\\nKnow more [here](https://aws.amazon.com/rds/aurora/?nc1=h_ls&aurora-whats-new.sort-by=item.additionalFields.postDateTime&aurora-whats-new.sort-order=desc)",
      "key": "Amazon Aurora",
      "id": "Amazon Aurora",
      "title": "Amazon Aurora",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "MongoDB is a document database, which means it stores data in JSON-like documents. We believe this is the most natural way to think about data, and is much more expressive and powerful than the traditional row/column model.\\n MongoDB is a true data platform with a comprehensive suite of tools to make working with data remarkably easy for everyone, from developers to analysts to data scientists.\\nKnow more [here](https://docs.mongodb.com/manual/)",
      "key": "Mongo DB",
      "id": "Mongo DB",
      "title": "Mongo DB",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Datical DB for SQL database improves and simplifies the application release process by automating database management.",
      "key": "Datical DB",
      "id": "Datical DB",
      "title": "Datical DB",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. Amazon Kinesis enables you to process and analyze data as it arrives and respond instantly instead of having to wait until all your data is collected before the processing can begin.",
      "key": "Kinesis",
      "id": "Kinesis",
      "title": "Kinesis",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "AWS IoT Core lets you connect IoT devices to the AWS cloud without the need to provision or manage servers. AWS IoT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS endpoints and to other devices reliably and securely. With AWS IoT Core, your applications can keep track of and communicate with all your devices, all the time, even when they aren\\'t connected",
      "key": "AWS IoT Core",
      "id": "AWS IoT Core",
      "title": "AWS IoT Core",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon DocumentDB (with MongoDB compatibility) is a fast, scalable, highly available, and fully managed document database service that supports MongoDB workloads. As a document database, Amazon DocumentDB makes it easy to store, query, and index JSON data",
      "key": "DocumentDB",
      "id": "DocumentDB",
      "title": "DocumentDB",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Quantum Ledger Database (Amazon QLDB) is a fully managed ledger database that provides a transparent, immutable, and cryptographically verifiable transaction log owned by a central trusted authority. You can use Amazon QLDB to track all application data changes, and maintain a complete and verifiable history of changes over time.",
      "key": "QLDB",
      "id": "QLDB",
      "title": "QLDB",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon ElastiCache offers fully managed Redis and Memcached. Seamlessly deploy, run, and scale popular open source compatible in-memory data stores. Build data-intensive apps or improve the performance of your existing apps by retrieving data from high throughput and low latency in-memory data stores",
      "key": "ElastiCache (Memcached)",
      "id": "ElastiCache (Memcached)",
      "title": "ElastiCache (Memcached)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon MQ is a managed message broker service for Apache ActiveMQ and RabbitMQ that makes it easy to set up and operate message brokers on AWS. Amazon MQ reduces your operational responsibilities by managing the provisioning, setup, and maintenance of message brokers for you. Because Amazon MQ connects to your current applications with industry-standard APIs and protocols, you can easily migrate to AWS without having to rewrite code.",
      "key": "Amazon MQ (Active MQ)",
      "id": "Amazon MQ (Active MQ)",
      "title": "Amazon MQ (Active MQ)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers. Amazon EC2\\'s simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon\\'s proven computing environment",
      "key": "EC2",
      "id": "EC2",
      "title": "EC2",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \"front door\" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications",
      "key": "API Gateway",
      "id": "API Gateway",
      "title": "API Gateway",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications.  The A2A pub/sub functionality provides topics for high-throughput, push-based, many-to-many messaging between distributed systems, microservices, and event-driven serverless applications. Using Amazon SNS topics, your publisher systems can fanout messages to a large number of subscriber systems",
      "key": "SQS/SNS",
      "id": "SQS/SNS",
      "title": "SQS/SNS",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to manage, and you pay only for the queries that you run",
      "key": "Amazon Athena",
      "id": "Amazon Athena",
      "title": "Amazon Athena",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon QuickSight is a scalable, serverless, embeddable, machine learning-powered business intelligence (BI) service built for the cloud. QuickSight lets you easily create and publish interactive BI dashboards that include Machine Learning-powered insights. QuickSight dashboards can be accessed from any device, and seamlessly embedded into your applications, portals, and websites.",
      "key": "QuickSight",
      "id": "QuickSight",
      "title": "QuickSight",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon MQ is a managed message broker service for Apache ActiveMQ and RabbitMQ that makes it easy to set up and operate message brokers on AWS. Amazon MQ reduces your operational responsibilities by managing the provisioning, setup, and maintenance of message brokers for you. Because Amazon MQ connects to your current applications with industry-standard APIs and protocols, you can easily migrate to AWS without having to rewrite code.",
      "key": "Amazon MQ (RabbitMQ)",
      "id": "Amazon MQ (RabbitMQ)",
      "title": "Amazon MQ (RabbitMQ)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon CloudWatch is a monitoring and observability service built for DevOps engineers, developers, site reliability engineers (SREs), and IT managers. CloudWatch provides you with data and actionable insights to monitor your applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. CloudWatch collects monitoring and operational data in the form of logs, metrics, and events, providing you with a unified view of AWS resources, applications, and services that run on AWS and on-premises servers",
      "key": "Cloudwatch",
      "id": "Cloudwatch",
      "title": "Cloudwatch",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "AWS WAF is a web application firewall that helps protect your web applications or APIs against common web exploits that may affect availability, compromise security, or consume excessive resources. AWS WAF gives you control over how traffic reaches your applications by enabling you to create security rules that block common attack patterns, such as SQL injection or cross-site scripting, and rules that filter out specific traffic patterns you define",
      "key": "WAF",
      "id": "WAF",
      "title": "WAF",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "STARC Simulation and Testing Cloud � SSTC, allows engineers to test, validate, and optimize product/software designs via a high-availability real-time cloud platform",
      "key": "Starc",
      "id": "Starc",
      "title": "Starc",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon DynamoDB is a fully managed proprietary NoSQL database service that supports key-value and document data structures and is offered by Amazon.com as part of the Amazon Web Services portfolio. DynamoDB exposes a similar data model to and derives its name from Dynamo, but has a different underlying implementation. Dynamo had a multi-master design requiring the client to resolve version conflicts and DynamoDB uses synchronous replication across multiple data centers for high durability and availability.",
      "key": "DynamoDB",
      "id": "DynamoDB",
      "title": "DynamoDB",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon ElastiCache offers fully managed Redis and Memcached. Seamlessly deploy, run, and scale popular open source compatible in-memory data stores. Build data-intensive apps or improve the performance of your existing apps by retrieving data from high throughput and low latency in-memory data stores",
      "key": "ElastiCache (Redis)",
      "id": "ElastiCache (Redis)",
      "title": "ElastiCache (Redis)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources. The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text.",
      "key": "Secrets Manager AWS",
      "id": "Secrets Manager AWS",
      "title": "Secrets Manager AWS",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Elastic Load Balancing (ELB) is a load-balancing service for Amazon Web Services (AWS) deployments. ELB automatically distributes incoming application traffic and scales resources to meet traffic demands",
      "key": "ELB - ALB",
      "id": "ELB - ALB",
      "title": "ELB - ALB",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Elastic Kubernetes Service (Amazon EKS) makes it easy to deploy, manage, and scale containerized applications using Kubernetes on AWS. Amazon EKS runs the Kubernetes management infrastructure for you across multiple AWS availability zones to eliminate a single point of failure",
      "key": "EKS",
      "id": "EKS",
      "title": "EKS",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon S3 or Amazon Simple Storage Service is a service offered by Amazon Web Services (AWS) that provides object storage through a web service interface. Amazon S3 uses the same scalable storage infrastructure that Amazon.com uses to run its global e-commerce network. Amazon S3 can be employed to store any type of object which allows for uses like storage for Internet applications, backup and recovery, disaster recovery, data archives, data lakes for analytics, and hybrid cloud storage  In its service-level agreement",
      "key": "S3",
      "id": "S3",
      "title": "S3",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon CloudFront is a content delivery network (CDN) offered by Amazon Web Services. Content delivery networks provide a globally-distributed network of proxy servers which cache content, such as web videos or other bulky media, more locally to consumers, thus improving access speed for downloading the content",
      "key": "CloudFront",
      "id": "CloudFront",
      "title": "CloudFront",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "IBM API Management(with version 5 renamed to IBM API Connect) is an API Management platform for use in the API Economy. IBM API Connect enables users to create, assemble, manage, secure and socialize web application programming interfaces (APIs).It provides a developer portal for application developers and to view published APIs. An administration portal allows users to establish policies for APIs such as self-registration, quotas, key management and security policies. An analytics engine provides role-based analytics for API owners, solution administrators and application developers in order to manage APIs and ensure service levels are being achieved",
      "key": "API Connect",
      "id": "API Connect",
      "title": "API Connect",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Microsoft Azure Active Directory is a comprehensive identity and access management cloud solution that combines core directory services, application access management, and advanced identity protection",
      "key": "AADP",
      "id": "AADP",
      "title": "AADP",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Docker is a tool designed to make it easier to create, deploy, and run applications by using containers. Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and ship it all out as one package. By doing so, thanks to the container, the developer can rest assured that the application will run on any other Linux machine regardless of any customized settings that machine might have that could differ from the machine used for writing and testing the code.",
      "key": "Docker",
      "id": "Docker",
      "title": "Docker",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Azure DevOps is the evolution of VSTS (Visual Studio Team Services). It is the result of years of using their own tools and developing a process for building and delivering products in an efficient and effective way.  ",
      "key": "Azure DevOps",
      "id": "Azure DevOps",
      "title": "Azure DevOps",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Dynatrace is a software intelligence company providing application performance management (APM), artificial intelligence for operations (AIOps), cloud infrastructure monitoring, and digital experience management (DEM), with products for the information technology departments and digital business owners of medium and large businesses",
      "key": "Dynatrace",
      "id": "Dynatrace",
      "title": "Dynatrace",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**[Istio](https://istio.io/)** is becoming the  factor of  infrastructure to operationalize a [microservices](https://martinfowler.com/articles/microservices.html) ecosystem. Its out-of-the-box implementation of cross-cutting concerns — such as service discovery, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency — has been bootstrapping our microservices implementations very quickly. It\\'s the main implementation of the service mesh technique we\\'ve been using. We\\'ve been enjoying its monthly releases and its continuous improvements with seamless upgrades. We use Istio to bootstrap our projects, starting with observability (tracing and telemetry) and service-to-service security. We\\'re closely watching its improvements to service-to-service authentication everywhere in and outside of the mesh. We\\'d also like to see Istio establish best practices for configuration files to strike a balance between giving autonomy to service developers and control to the service mesh operators.",
      "key": "Istio",
      "id": "Istio",
      "title": "Istio",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**Kobiton** is a mobile device testing platform that accelerates the testing and delivery of mobile applications by offering live device testing in the cloud, or on-premise.\\n Know more [here](https://kobiton.com)",
      "key": "Kobiton",
      "id": "Kobiton",
      "title": "Kobiton",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**JFrog Artifactory** is a universal DevOps solution providing end-to-end automation and management of binaries and artifacts through the application delivery process that improves productivity across your development ecosystem. It enables freedom of choice supporting 25+ software build packages, all major CI/CD platforms, and DevOps tools you already use. Artifactory is Kubernetes ready supporting containers, Docker, Helm Charts, and is your Kubernetes and Docker registry and comes with full CLI and REST APIs customizable to your ecosystem.\\nKnow more [here](https://www.jfrog.com/confluence/display/JFROG/JFrog+Artifactory)",
      "key": "Artifactory",
      "id": "Artifactory",
      "title": "Artifactory",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**SonarQube®** is an automatic code review tool to detect bugs, vulnerabilities, and code smells in your code. It can integrate with your existing workflow to enable continuous code inspection across your project branches and pull requests.\\n Know more [here](https://docs.sonarqube.org/latest/)",
      "key": "Sonar",
      "id": "Sonar",
      "title": "Sonar",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**Kiuwan** is an End-to-end application security platform for every stage and all the stakeholders in the SDLC. OWASP, CWE, PCI-DSS, NIST. It is useful as Security Solutions for DevOps Process, giving an Effective static application security testing and software composition analysis. Also, it is an affordable solutions for teams of all sizes.\\nKnow more [here](https://www.kiuwan.com)",
      "key": "Kiuwan",
      "id": "Kiuwan",
      "title": "Kiuwan",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**OpenShift** is a Kubernetes superset combining over 200 open source projects into a fully integrated solution with strong focus on a developer experience, operational capabilities, monitoring, and management with strong and secure defaults. All these while being pluggable so platform admins can replace out of the box components and services with their own.\\nKnow more [here](https://www.openshift.com)",
      "key": "OpenShift",
      "id": "OpenShift",
      "title": "OpenShift",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**AWS CodeDeploy** is a fully managed deployment service that automates software deployments to a variety of compute services such as Amazon EC2, AWS Fargate, AWS Lambda, and your on-premises servers. AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications. You can use AWS CodeDeploy to automate software deployments, eliminating the need for error-prone manual operations. The service scales to match your deployment needs.\\nKnow more [here](https://www.openshift.com)",
      "key": "AWS CodeDeploy",
      "id": "AWS CodeDeploy",
      "title": "AWS CodeDeploy",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**HockeyApp** is a service that allows developers to recruit and manage testers, distribute apps, and collect crash reports, among other things. It started out as a way to install beta apps on iOS devices, a process that Apple calls “ad hoc” distribution, or installing apps outside of the official App Store. From the words ad hoc, it was named Hockey. Currently, the project was retired.\\n Know more [here](https://devblogs.microsoft.com/appcenter/hockeyapp-is-being-retired/)",
      "key": "HokeyApp",
      "id": "HokeyApp",
      "title": "HokeyApp",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**GitHub** is a code hosting platform for version control and collaboration. It lets you and others work together on projects from anywhere. This tutorial teaches you GitHub essentials like repositories, branches, commits, and Pull Requests.\\n Know more [here](https://github.com)",
      "key": "Github",
      "id": "Github",
      "title": "Github",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**AWS Lambda** is a serverless compute service that runs your code in response to events and automatically manages the underlying compute resources for you. You can use AWS Lambda to extend other AWS services with custom logic, or create your own back-end services that operate at AWS scale, performance, and security. AWS Lambda can automatically run code in response to multiple events, such as HTTP requests via Amazon API Gateway, modifications to objects in Amazon S3 buckets, table updates in Amazon DynamoDB, and state transitions in AWS Step Functions.\\n Know more [here](https://github.com)",
      "key": "AWS Lambda",
      "id": "AWS Lambda",
      "title": "AWS Lambda",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**Rational Team Concert™** is a team collaboration tool that is built on a scalable, extensible platform. Rational Team Concert uses the Change and Configuration Management (CCM) application to provide features that integrate development project tasks including iteration planning, process definition, change management, defect tracking, source control, build automation, and reporting.\\n Know more [here](https://www.ibm.com/support/knowledgecenter/en/SSYMRC_6.0.0/com.ibm.team.concert.doc/topics/c_product-overview.html)",
      "key": "Rational Team Concert",
      "id": "Rational Team Concert",
      "title": "Rational Team Concert",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**Feature Flags or Feature Toogles **is a technique widely used by new architectures and deployment models that require the release of features in a fast and safe way for the user experience, allowing enabling or disabling features in production without the need to redeploy to all users or specific user segments, favors the practice of Trunk Based Development, as well as hot variations of features on mobile devices where it is difficult to achieve an update of all users.\\n Know more [aquí](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/6756/Cultura-Feature-Flags)",
      "key": "Feature Flags Bancolombia",
      "id": "Feature Flags Bancolombia",
      "title": "Feature Flags Bancolombia",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**UrbanCode** is a build management, deployment automation and release management solutions that can enable continuous delivery for any combination of on-premises, cloud and mainframe applications by eliminating manual, error-prone processes. \\n Know more [here](https://www.ibm.com/cloud/urbancode)",
      "key": "UrbanCode",
      "id": "UrbanCode",
      "title": "UrbanCode",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "[Fluid Asserts](https://fluidattacks.com/resources/doc/asserts/#:~:text=Fluid%20Asserts%20is%20an%20engine,of%20many%20protocols%20(DXST).) is an engine to automate the closing of security findings over execution environments. Asserts performs Dynamic and Static Application Security Testing (DAST and SAST) and dynamic testing of many protocols (DXST). \\nAsserts reuses previously handcrafted attack vectors in order to automate the closing of vulnerabilities. This makes it particularly useful since this testing can be performed by end users as-is or as part of a continuous integration pipeline. Thus any changes to the Target of Evaluation (ToE) can be continuously tested against the closing of confirmed vulnerabilities.\\n",
      "key": "Fluid Asserts",
      "id": "Fluid Asserts",
      "title": "Fluid Asserts",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "**[Kafka Streams](https://kafka.apache.org/documentation/streams/)** is a lightweight library to build streaming applications. It supports basic streaming APIs such as join, filter, map and aggregate as well as local storage for common use cases such as windowing and sessions. Unlike other stream-processing platforms such as Apache Spark and [Alpakka Kafka](https://doc.akka.io/docs/akka-stream-kafka/current/home.html), Kafka Streams has been a good fit for scenarios that don\\'t require large-scale distribution and parallel processing; hence we could get away without yet another piece of infrastructure such as cluster schedulers. Naturally, Kafka Streams has been a good choice when operating in the Kafka ecosystem. Kafka Streams is particularly useful when we have to process data strictly in order and exactly once. One particular use case of Kafka Streams is to build a [change data capture (CDC)](https://en.wikipedia.org/wiki/Change_data_capture#Event_Programming) platform.",
      "key": "Kafka Streams",
      "id": "Kafka Streams",
      "title": "Kafka Streams",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "We\\'ve seen significant benefits from introducing [microservices](https://martinfowler.com/articles/microservices.html), which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we\\'ve also seen many teams create a frontend monolith — a large, entangled browser application that sits on top of the backend services — largely neutralizing the benefits of microservices. Since we first described **micro frontends** as a technique to address this issue, we\\'ve had almost universally positive experiences with the approach and have found a number of patterns to use micro frontends even as more and more code shifts from the server to the web browser. So far, web components have been elusive in this field, though.",
      "key": "Microfrontends",
      "id": "Microfrontends",
      "title": "Microfrontends",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Humans and machines use secrets throughout the value stream of building and operating software. The build pipelines need secrets to interface with secure infrastructures such as container registries, the applications use API keys as secrets to get access to business capabilities, and the service-to-service communications are secured using certificates and keys as secrets. You can set and retrieve these secrets in different ways. We\\'ve long cautioned developers about using source code management for storing secrets. We\\'ve recommended decoupling secret management from source code and using tools such as git-secrets and Talisman to avoid storing secrets in the source code. We\\'ve been using **secrets as a service** as a default technique for storing and accessing secrets. With this technique you can use tools such as Vault or [AWS Key Management Service (KMS)](https://aws.amazon.com/kms/) to read/write secrets over an HTTPS endpoint with fine-grained levels of access control. Secrets as a service uses external identity providers such as [AWS IAM](https://aws.amazon.com/iam/) to identify the actors who request access to secrets. Actors authenticate themselves with the secrets service. For this process to work, it\\'s important to automate bootstrapping the identity of the actors, services and applications. Platforms based on SPIFFE have improved the automation of assigning identities to services.",
      "key": "Secrets as a service",
      "id": "Secrets as a service",
      "title": "Secrets as a service",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "In the last year we have seen **Chaos Engineering** go from being a much talked about idea to an accepted, widely accepted idea to improve and ensure the resiliency of distributed systems. As organizations large and small begin to implement Chaos Engineering as an operational process, we are learning how to safely apply these techniques on a large scale. The approach is definitely not for everyone and to be effective and secure requires large-scale organizational support. Industry acceptance and availability of experts will definitely increase with the advent of commercial services such as Gremlin and deployment tools such as Spinnaker implementing some Chaos Engineering tools. Check [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/12088/Continuous-Chaos) regarding Chaos Engineering in Bancolombia.",
      "key": "Chaos Engineering",
      "id": "Chaos Engineering",
      "title": "Chaos Engineering",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The container revolution around Docker has massively reduced the friction in moving applications between environments, fueling increased adoption of continuous delivery and continuous deployments. The latter, especially, has blown a rather large hole in the traditional controls over what can go to production. The technique of **container security scanning** is a necessary response to this threat vector. Tools in the build pipeline automatically check containers flowing through the pipeline against known vulnerabilities. Since our first mention of this technique, the tool landscape has matured and the technique has proven useful on development efforts with our clients.",
      "key": "Container security scanning",
      "id": "Container security scanning",
      "title": "Container security scanning",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Service mesh** is an approach to operating a secure, fast and reliable microservices ecosystem. It has been an important stepping stone in making it easier to adopt microservices at scale. It offers discovery, security, tracing, monitoring and failure handling. It provides these cross-functional capabilities without the need for a shared asset such as an API gateway or baking libraries into each service. A typical implementation involves lightweight reverse-proxy processes, aka sidecars, deployed alongside each service process in a separate container. Sidecars intercept the inbound and outbound traffic of each service and provide cross-functional capabilities mentioned above. This approach has relieved the distributed service teams from building and updating the capabilities that the mesh offers as code in their services. This has lead to an even easier adoption of polyglot programming in a microservices ecosystem. Our teams have been successfully using this approach with open source projects such as Istio and we will continue to monitor other open service mesh implementations such as [Linkerd](http://linkerd.io/) closely.",
      "key": "Service mesh",
      "id": "Service mesh",
      "title": "Service mesh",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "As infrastructures grow in complexity, so do the configuration files that define them. Tools such as [AWS CloudFormation](https://aws.amazon.com/cloudformation/), Kubernetes and Helm expect configuration files in JSON or YAML syntax, presumably in an attempt to make them easy to write and process. However, in most cases, teams quickly reach the point where they have some parts that are similar but not quite the same, for example, when the same service must be deployed in different regions with a slightly different setup. For such cases tools offer **templating in YAML** (or JSON), which has caused a huge amount of [frustration with practitioners](https://leebriggs.co.uk/blog/2019/02/07/why-are-we-templating-yaml.html). The problem is that the syntax of JSON and YAML requires all sorts of awkward compromises to graft templating features such as conditionals and loops into the files. We recommend using an API from a programming language instead or, when this is not an option, a templating system in a programming language, either a general-purpose language such as Python or something specialized such as [Jsonnet](https://jsonnet.org/).",
      "key": "Templating in YAML",
      "id": "Templating in YAML",
      "title": "Templating in YAML",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Oauth is an open standard for the secure handling of the authorization process of applications consuming an HTTP resource. This is provided as a framework that allows providing access from a service provider to third-party applications through authorization flows. **At Bancolombia we use Oauth 2.0, which is the evolution of the original Oauth standard**",
      "key": "OAuth",
      "id": "OAuth",
      "title": "OAuth",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "This practice is carried out thanks to the use of SonarQube and Kiuwan, static code analysis tools involved in the development life cycle to avoid bad coding practices in production. They act in a contextual way during the development process itself, through the use of plugins in the IDE that guarantee proactive analysis, seeking to prevent pipeline breakage, as well as in the CD pipeline, which contains the necessary tasks to execute this task. . This last inclusion in the life cycle has the ability to break the pipeline, in the case of finding any bad practice. You can see the guideline below Continuous verification of vulnerabilities (Sonar, Kiuwan)[Verificación continua de vulnerabilidades (Sonar, Kiuwan)​](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/4559/Instalación-SonarLint-y-Sonar-Scanner)",
      "key": "Continuous vulnerability checking (Sonar, Kiuwan)",
      "id": "Continuous vulnerability checking (Sonar, Kiuwan)",
      "title": "Continuous vulnerability checking (Sonar, Kiuwan)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "the **http security headers**  are a subset of the http headers. They are configurations with a *key-value* structure, where the key is case-sensitive and followed by a colon (:) with which the external domains that can interact with our backend can be defined, through XMLhttpRequest requests made from a browser. The headers are interpreted by the browser to determine if the request to be made can be carried out.",
      "key": "Headers de Seguridad HTTP​",
      "id": "Headers de Seguridad HTTP​",
      "title": "Headers de Seguridad HTTP​",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "An encryption algorithm is a component for the security of electronic data transport. The actual mathematical steps are taken and listed when developing algorithms for encryption purposes, and different block ciphers are used to encrypt electronic data or numbers.",
      "key": "Algorithms and encryption protocols",
      "id": "Algorithms and encryption protocols",
      "title": "Algorithms and encryption protocols",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Las **Security considerations in Cloud-native applications are carried out through the[Software Engineering Practices for Secure Development or DevSecOps](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/594/Desarrollo-seguro), which seek to shield the application as much as possible against the different threats and security risks, avoiding vulnerabilities. of various kinds that make possible a materialization of the threat, through mechanisms such as security in Docker images, storage of tokens in SPAs, generation and management of digital certificates, use of linters and static analysis of code such as SonarLint and Sonar Scanner, among others.**",
      "key": "Security considerations in cloud native applications",
      "id": "Security considerations in cloud native applications",
      "title": "Security considerations in cloud native applications",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**ACID** is an acronym that stands for Atomicity, Consistency, Isolation and Durability, characteristics of SQL databases, and that basically guarantee consistency and availability but are not easily distributed or tolerant to partitioning as indicated in the  [CAP theorem](https://grupobancolombia.visualstudio.com/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/1773/Tipos-de-bases-de-datos). There is Eventual Consistency when there is Eventual Delivery, Convergence and Termination. Strong Eventual Consistency occurs when there is Strong Convergence. This practice is often a good option for keeping data immutable in distributed systems, but it is not suitable for all cases. You can see below the guideline on [Strong Eventual Consistency (ACID 2.0)](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/9425/Strong-Eventual-Consistency-(ACID-2.0))",
      "key": "Strong eventual consistency (ACID 2.0)​",
      "id": "Strong eventual consistency (ACID 2.0)​",
      "title": "Strong eventual consistency (ACID 2.0)​",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**CQRS (Command Query Responsibility Segregation)** is an architectural pattern in which we have two differentiated subsystems, one responsible for the commands, and the other responsible for the queries, that is, reading and writing go through paths different.",
      "key": "CQRS",
      "id": "CQRS",
      "title": "CQRS",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "A **Conflict-free Replicated Data Type (CRDT)** is a data structure that simplifies distributed data storage systems and multi-user applications. \\nIn many systems, copies of some data need to be stored on multiple computers (known as replicas). Examples of such systems include: Mobile apps; Distributed databases; Collaboration software, such as Google Docs, Trello, Figma and Large-scale data storage and processing systems. \\nAll such systems need to deal with the fact that the data may be concurrently modified on different replicas. Broadly speaking, there are two possible ways of dealing with such data modifications: Strongly consistent replication and Optimistic replication. \\n Know more [here](https://crdt.tech)",
      "key": "Conflict-free replicated data types (CRDTs)​",
      "id": "Conflict-free replicated data types (CRDTs)​",
      "title": "Conflict-free replicated data types (CRDTs)​",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Distributed in-memory application data caches like memcached are a popular solution for scaling database-driven web sites. These systems are easy to add to existing deployments, and increase performance significantly by reducing load on both the database and application servers. Unfortunately, such caches do not integrate well with the database or the application. They cannot maintain transactional consistency across the entire system, violating the isolation properties of the underlying database. \\nThey leave the application responsible for locating data in the cache and keeping it up to date, a frequent source of application complexity and programming errors. \\nAddressing both of these problems, there are options as transactional caches. Some cases shows that adding a transactinoal cache can increase the throughput of a web application by up to 5.2×, only slightly less than a non-transactional cache, showing that consistency does not have to come at the price of performance.\\n Know more reading the article[Transactional Consistency and Automatic Management in an Application Data Cache](https://drkp.net/papers/txcache-osdi10.pdf), published by Dan R. K. Ports, Austin T. Clements, Irene Zhang, Samuel Madden and Barbara Liskov in MIT CSAIL.",
      "key": "Consistency and effective use of cache",
      "id": "Consistency and effective use of cache",
      "title": "Consistency and effective use of cache",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The concepts of transaction and of data consistency are defined for a distributed system. The cases of partitioned data, where fragments of a file are stored at multiple nodes, and replicated data, where a file is replicated at several nodes, are discussed. It is argued that the distribution and replication of data should be transparent to the programs which use the data. That is, the programming interface should provide location transparency, replica transparency, concurrency transparency, and failure transparency. Techniques for providing such transparencies are abstracted and discussed. \\nBy extending the notions of system schedule and system clock to handle multiple nodes, it is shown that a distributed system can be modeled as a single sequential execution sequence. This model is then used to discuss simple techniques for implementing the various forms of transparency. \\nAll such systems need to deal with the fact that the data may be concurrently modified on different replicas. Broadly speaking, there are two possible ways of dealing with such data modifications: Strongly consistent replication and Optimistic replication. \\n Know more [official paper](https://dl.acm.org/doi/10.1145/319732.319734)",
      "key": "Consistency in transactions and distributed processes",
      "id": "Consistency in transactions and distributed processes",
      "title": "Consistency in transactions and distributed processes",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "At very first, Saga pattern was proposed by Hector García-Molina and Kenneth Salem as a sophisticated solution for the Long lived Transactions problem. A LLT is a saga if it can be written as a sequence of transactions that can be interleaved with other transactions The database management system guarantees that either all the transactions m a saga are successfully completed or compensatmg transactions are run to amend a partial execution Both the concept of saga and its lmplementation are relatively simple, but they have the potential to improve performance slgmficantly. Chris Richardsion defines a saga as *a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.*\\n Know more reading the original García-Molina and Salem\\'s paper titled[ Sagas](https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf) and [Chris Richardson\\'s definition](https://microservices.io/patterns/data/saga.html)",
      "key": "Compensation transactions- Saga pattern",
      "id": "Compensation transactions- Saga pattern",
      "title": "Compensation transactions- Saga pattern",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Immutable data / Append-Only Apps​ are qualities contained within append-only computing. In append-only computing, observations are recorded forever (or for a long time). Derived results are calculated on demand (or periodically precalculated). \\nThis is similar to a DBMS (database management system) in which transaction logs record all the changes made to the database. High-speed appends are the only way to change the log. From this perspective, the contents of the database hold a caching of the latest record values in the logs. The truth is the log. The database is a cache of a subset of the log. That cached subset happens to be the latest value of each record and index value from the log. \\nYou can learn more about [Immutable data / Append-Only Apps​](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/12436/Event-First-Domain-driven-Design-(DDD))",
      "key": "Immutable data / Append-Only Apps",
      "id": "Immutable data / Append-Only Apps",
      "title": "Immutable data / Append-Only Apps",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Currently there is a wide range of both type and brand, each with a defined objective and capabilities. For this reason, it is important to know the guide to recognize the **Limitations and characteristics of different SQL/NoSQL​** distributed data models. \\nLet us remember Brewer\\'s theorem or CAP theorem, which mentions three characteristics, indicating that databases can only take two: \\nIn the case of relational databases (Relational Data Base Management Systems) Usually you have Consistency and Availability, while non-relational databases usually have a combination of Availability and Partitioning or Consistency and Partitioning.\\n Learn more about this guide [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/1773/Tipos-de-bases-de-datos)",
      "key": "Limitations and characteristics of different SQL/NoSQL distributed data models",
      "id": "Limitations and characteristics of different SQL/NoSQL distributed data models",
      "title": "Limitations and characteristics of different SQL/NoSQL distributed data models",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Retry is a fairly simple pattern that is useful when you get an unexpected response or no response at all. Simply, it is about the number of retries that an application can execute in order to obtain the expected response for a request. In order for the pattern to be used successfully, the retries must be able to be configured a certain number of times. It is useful when there are network problems, internal errors of the consumed server, because there are no responses or they are very slow. It is useless if the component to consume is overloaded with requests. In Bancolombia, the Retry pattern is not applied alone, it is done in conjunction with **Circuit Breaker**. It is often useful for some operations that use Retry to be idempotent. **Idempotency** is a property used in mathematics and computer science, where certain operations can be applied multiple times without changing the result after the first interaction. It is applied in scenarios where the client can make retries on the request and where these can generate untimely changes or damage. Apply Idempotence preferably in relevant operations, as this operation can add latencies, so it is not recommended in all operations. This can be done through the use of **idempotence http headers**. See the guidelines of [Retry](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/8547/Circuit-breakers-and-Fallback-strategy) e [ Idempotence](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7826/Idempotencia)",
      "key": "Retry and idempotence",
      "id": "Retry and idempotence",
      "title": "Retry and idempotence",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Location Transparency is a quality of a distributed systems that allows decoupling in space (see the the definition for Isolation), enabled through asynchronous message-passing, and decoupling of the runtime instances from their references. This approach is ideal for non static system topology and deployment model upfront scenarios. \\nKnow more [here](https://www.reactivemanifesto.org/glossary#Location-Transparency)",
      "key": "Location Transparency​",
      "id": "Location Transparency​",
      "title": "Location Transparency​",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Fault Tolerance y Recovery pattern hacen referecia a los patrones de Circuit Breaker, Fallback y Retry. Conoce más de ellos en el lineamiento sobre [Circuit breakers, Retry and Fallback strategy](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/8547/Circuit-breakers-and-Fallback-strategy)",
      "key": "Fault tolerance and recovery patterns",
      "id": "Fault tolerance and recovery patterns",
      "title": "Fault tolerance and recovery patterns",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Health check** is a pattern used to tell the system if everything is fine with an instance of the application that is deployed. To carry out this practice in Bancolombia, we rely on the capabilities provided by k8s for it, **Liveness** and **Readiness probes**, which seek to indicate if an instance is responding and when ready after getting up, respectively.",
      "key": "Health check/K8",
      "id": "Health check/K8",
      "title": "Health check/K8",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Self-healing deployments** is a practice that guarantees the high availability of applications. To achieve a self-healing infrastructure, you need a tool that does such a job. At Bancolombia we have it and this is Kubernetes. In this case, the same tool that orchestrates the containers in the Cloud cluster is the one that acts as the curator of the deployments. The native Kubernetes container orchestrator capabilities make this possible, without requiring additional use of other Kubernetes capabilities. This is achieved with the proper configuration of the **deployment.yaml** file. However, it is possible to optimize this task with the use of the Kubernetes probes (Liveness and Readiness), thus favoring high availability and responsiveness of the applications. You can see below the practices that favor Self-healing: [Health check.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7363/Health-Check)",
      "key": "Self Healing deployments (Container orchestation)",
      "id": "Self Healing deployments (Container orchestation)",
      "title": "Self Healing deployments (Container orchestation)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Concurrency safe code uses certain techniques to address best practices to help you write clear and correct concurrent programs. With this practice, the typical and undesirable problems of concurrent systems, with multiple threads, frequent in languages such as Java, are solved. As Bancolombia has the majority of legacy and cloud-native applications made in this concurrent language, it is necessary to specify the compliance of these techniques in the code. Some of these techniques are Stateless implementations, Immutable implementations, Atomic Variable Class, among many others, contained in the guideline of [Concurrency Safe Code](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/8157/Concurrency-Safe-Code%E2%80%8B)",
      "key": "Concurrency safe code",
      "id": "Concurrency safe code",
      "title": "Concurrency safe code",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Bulkheads are used in ships to create seperate watertight compartments which serve to limit the effect of a failure - ideally preventing the ship from sinking. If water breaks through the hull in one compartment, the bulkheads prevent it from flowing into other compartments, limiting the scope of the failure. \\nThis same concept is useful in the architecture of large systems for the same reason - limiting the scope of failure. \\nKnow more [here](https://skife.org/architecture/fault-tolerance/2009/12/31/bulkheads.html)",
      "key": "Fault isolation / Isolate all the things - Bulkheading.",
      "id": "Fault isolation / Isolate all the things - Bulkheading.",
      "title": "Fault isolation / Isolate all the things - Bulkheading.",
      "timeline": [
        {
          "moved": 0,
          "ringId": "hold",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Traceable and observable systems / logs management (Back/front) (Observability/audit))** help verify that developments are refined and working correctly. In addition, it helps analysts to understand any strange platform behavior and ensure that there is no failing method. Unfortunately, in many cases they fail to define and implement effective traceability, because the traces are created without following the standards, generating inconsistencies in the information recorded and, often, incomplete. \\nLearn more [aquí](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/8238/Traceable-and-observable-systems-logs-management)",
      "key": "Traceable and observable systems / logs management (Back/front)",
      "id": "Traceable and observable systems / logs management (Back/front)",
      "title": "Traceable and observable systems / logs management (Back/front)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **Circuit Breaker** pattern consists of encapsulating and monitoring the requests, resulting in three phases of the circuit: open circuit (the operations are not executed and an auxiliary pattern such as fail fast or fallback is used). ), half-open circuit (temporary and periodic execution of requests) and closed circuit (all invocations to the service are executed). Fallback is a pattern that consists of looking for an alternative that processes the request successfully while the main service is not available, or returning empty information when it is optional information. You can see the complete guideline on [Circuit breakers and Fallback strategy](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/8547/Circuit-breakers-and-Fallback-strategy)",
      "key": "Fallback strategy and Circuit breakers",
      "id": "Fallback strategy and Circuit breakers",
      "title": "Fallback strategy and Circuit breakers",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "** Redundancy:** describes the fact that you have more than one node/component/process in a system and it\\'s pretty useful for handling failovers. In the case that one of your nodes fail, another node in the system can take over and carry on. \\n** Replication:** includes redundancy, but involves the copying of data from one node to another or the synchronization of state between nodes. An example of where replication is done is at the databases or MQs level that forms a cluster",
      "key": "Replication and redundance",
      "id": "Replication and redundance",
      "title": "Replication and redundance",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Reactor and other reactive programming frameworks offer the possibility of developing non-blocking threads on top of the JVM. When we talk about a non-blocking stream, we mean an asynchronous stream that allows efficient management of demand (backpressure) and integrates directly with the functional APIs of Java 8. \\nOne of the advantages of asynchronous streams is that they do not lock the system completely but allow parallel execution of asynchronous processes. This is made possible by the Reactive Streams specification, an initiative that provides a standard for non-blocking backpressure asynchronous stream processing. \\nLearn more  [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/16136/Uso-de-Flujos-asíncronos-y-no-bloqueantes)",
      "key": "Asynchronous and non-blocking streams",
      "id": "Asynchronous and non-blocking streams",
      "title": "Asynchronous and non-blocking streams",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Event Sourcing** is an architectural pattern that is responsible for capturing all the changes that may occur in the application as a sequence of events. You can see the complete guideline on [Event Sourcing](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/10834/Event-Sourcing)",
      "key": "Event Sourcing",
      "id": "Event Sourcing",
      "title": "Event Sourcing",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Event-First Domain-driven Design (DDD)** refers to a set of design principles that have been used for some years and have proven to be of great utility for building large-scale distributed systems. \\nIt consists of understanding the essence of a domain from the flow of data and not from isolated entities, becoming an alternative to traditional software design. This alternative seeks an interdisciplinary understanding of the problem to be solved, without focusing only on filling out templates and formats, but mainly on telling stories from a business language. \\nLearn more [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/12436/Event-First-Domain-driven-Design-(DDD))",
      "key": "Event first Domain driven design",
      "id": "Event first Domain driven design",
      "title": "Event first Domain driven design",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Also known as event stream processing, Data Streaming is the continuous flow of data generated by one or multiple sources of information, whose information can be stored, processed and analyzed as it is generated in real time, it must be kept in mind that the use of Data Stream implies the treatment of data by data of a set of information, instead of treating all the data at a given moment, thus making a leap from the concept of data at rest (data at rest) towards data in motion (data in motion).",
      "key": "Event Streaming Platforms (Event streams) / \"data at rest\" to \"data in motion.",
      "id": "Event Streaming Platforms (Event streams) / \"data at rest\" to \"data in motion.",
      "title": "Event Streaming Platforms (Event streams) / \"data at rest\" to \"data in motion.",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "When we talk about microservices architecture, we mean at a high level a set of independent modules that collaborate to achieve a larger business goal. A reactive system is a robust distributed system, for which the message-driven asynchronous communication approach is essential. The event-driven architecture paradigm is a distributed asynchronous architecture model used to produce highly scalable applications composed of single-purpose, highly decoupled event processing components that receive and process events asynchronously. The practice set forth in this definition focuses primarily on the semantics of commands and events. \\nLearn more  [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/11539/Event-driven-architecture-(Commands-and-Events))",
      "key": "Event driven architecture (Commands and Events)",
      "id": "Event driven architecture (Commands and Events)",
      "title": "Event driven architecture (Commands and Events)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "When we talk about reactive systems we refer to distributed systems with certain qualities, which although they were compiled and described concisely in the reactive systems manifesto, it does not mean that these qualities are new or previously unknown. In fact, the vast majority of its fundamental principles date back to the design and implementation of Erlang/OTP by Ericsson, whose development began in the late 1980s. \\nReactive programming will be the basis in many contexts for improving responsiveness, facilitating the management of asynchronous flows, in addition to increasing scalability and efficiency in the use of resources.\\nIn addition, to achieve a high emphasis on the maintainability and extensibility of the system, n both **functional programming principles and patterns**, as well as a disciplined separation of responsibilities and levels of abstraction in the software structure. \\nLearn more [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/13807/Foundation-Sistemas-Reactivos)",
      "key": "Fuctional reactive programming",
      "id": "Fuctional reactive programming",
      "title": "Fuctional reactive programming",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "When a certain action can fail and you want the system to be resilient to this particular failure, in some cases the approach should be to simply let another, higher-level component handle the failure, but in others you should enable patterns of failure. fault tolerance such as: Alternative flows (fallback), Default values in case of error, Controlled retries with an exponential \\'backoff\\' (wait time between retries).",
      "key": "Message Retry strategies: Dead letters, queue backlogs... manual message retry",
      "id": "Message Retry strategies: Dead letters, queue backlogs... manual message retry",
      "title": "Message Retry strategies: Dead letters, queue backlogs... manual message retry",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Autoscale up and down** is a practice that seeks to autoscale Cloud-native applications. Obviously, it supports the scalability of solutions in Bancolombia. Cloud native technologies like Kubernetes allow you to build applications that adapt to changing loads. Kubernetes ** Autoscaling ** allows us to define a variable capacity for an application, which is not fixed, but guarantees enough capacity to handle a different load. The most direct approach to achieving such behavior is by using a **Horizontal Pod Autoscaler (HPA)** to horizontally scale the number of pods in the architecture. Find the definition in the wiki below: [HPA](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/1977/HPA-Horizontal-Pod-Autoscaling)",
      "key": "Elastic (Auto scale out/down) deployments -Container Orchestation",
      "id": "Elastic (Auto scale out/down) deployments -Container Orchestation",
      "title": "Elastic (Auto scale out/down) deployments -Container Orchestation",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Concurrent programming deals with the study and development of programs that can perform several tasks at the same time. When combined with an asynchronous model, threads are not blocked, making the system more fault tolerant",
      "key": "Concurrency models optimized for asynchronous and high concurrency",
      "id": "Concurrency models optimized for asynchronous and high concurrency",
      "title": "Concurrency models optimized for asynchronous and high concurrency",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "When we talk about reactive systems we refer to distributed systems with certain qualities, which although they were compiled and described concisely in the reactive systems manifesto, it does not mean that these qualities are new or previously unknown. In fact, the vast majority of its fundamental principles date back to the design and implementation of Erlang/OTP by Ericsson, whose development began in the late 1980s. \\nReactive programming will be the basis in many contexts for improving responsiveness, facilitating the management of asynchronous flows, in addition to increasing scalability and efficiency in the use of resources.\\nIn addition, to achieve a high emphasis on the maintainability and extensibility of the system, n both **functional programming principles and patterns**, as well as a disciplined separation of responsibilities and levels of abstraction in the software structure. \\nLearn more [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/13807/Foundation-Sistemas-Reactivos)",
      "key": "Reactive programming",
      "id": "Reactive programming",
      "title": "Reactive programming",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Communications between processes are generally implemented by passing messages with a synchronous request-response style or event-driven asynchronous styles. In the synchronous style of communication, the client process sends a request message to the server process over the network and waits for a response message. In asynchronous event-based messaging, processes communicate with asynchronous message passing through an intermediary known as an event broker. Depending on your business use case, you can select the communication pattern you want to implement: Rsocket, gRPC, GraphQL, AMQP",
      "key": "Modern communication protocols (gRPC, Rsocket, etc..)",
      "id": "Modern communication protocols (gRPC, Rsocket, etc..)",
      "title": "Modern communication protocols (gRPC, Rsocket, etc..)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Connection pool** or pool of connections is what is commonly known as the number of possible open connections that can be established from a backend service to a Database. It is a set of threads that have a more or less permanent connection to a database. **Connection Pool Sizing** is an important practice to carry out, since it allows objective estimation of the number of connections that can be established to a database, avoiding leaving too low default figures or discharges that threaten performance. You can see the complete guideline on[Connection Pool Sizing](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/9493/Connection-pool-sizing)",
      "key": "Database connection pool sizing",
      "id": "Database connection pool sizing",
      "title": "Database connection pool sizing",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Reactor and other reactive programming frameworks offer the possibility of developing non-blocking threads on top of the JVM. When we talk about a non-blocking stream, we mean an asynchronous stream that allows efficient management of demand (backpressure) and integrates directly with the functional APIs of Java 8. \\nOne of the advantages of asynchronous streams is that they do not lock the system completely but allow parallel execution of asynchronous processes. This is made possible by the Reactive Streams specification, an initiative that provides a standard for non-blocking backpressure asynchronous stream processing. \\nLearn more [here�](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/16136/Uso-de-Flujos-asíncronos-y-no-bloqueantes)",
      "key": "End to end reactive/non-blocking flow",
      "id": "End to end reactive/non-blocking flow",
      "title": "End to end reactive/non-blocking flow",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Functional programming is more than a programming paradigm, that is, it is a way in which we can solve different problems, focusing on the What and not the How. The logic is expressed without describing flow controls; loops or conditionals",
      "key": "Declarative and functional approach",
      "id": "Declarative and functional approach",
      "title": "Declarative and functional approach",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "With this practice we seek a different approach when thinking about the organization, an approach that seeks to find and define the different layers by business models rather than defining silos or pre-established layers in the organization. In turn, it is leveraged in the practice of (DDD)[Event-First Domain-driven Design](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/12436/Event-First-Domain-driven-Design-(DDD)). Below you can learn more about: [Domain-centric structure.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/12626/Domain-contexts-instead-of-Layered-Silos%E2%80%8B)",
      "key": "Domain centered structure",
      "id": "Domain centered structure",
      "title": "Domain centered structure",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The practice of **Design of internal APIs** seeks that the internal application APIs follow a standard to be designed and documented. For this, the creation of the API contract with Swagger is required, following OAS (OpenAPI Specification), which is a widely known and accepted format for designing and documenting REST APIs. You can see the complete guideline on [Practice Design of internal APIs](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/10038/Práctica-Diseño-de-APIs-internas)",
      "key": "Design of APIs / Contracts defined",
      "id": "Design of APIs / Contracts defined",
      "title": "Design of APIs / Contracts defined",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "In the functional programming paradigm, functions are the basic building blocks, all values are immutable and the code is declarative, favoring the expressiveness of developments over declarations that are used in this type of language only to control the flow of programs, here we talk about pure functions, referential transparency and immutability.",
      "key": "Functional patterns and abstractions (for reactive and non-reactive systems)",
      "id": "Functional patterns and abstractions (for reactive and non-reactive systems)",
      "title": "Functional patterns and abstractions (for reactive and non-reactive systems)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Patterns are considered: Currying, Closures, Tail recursion and Pattern Matching",
      "key": "Patterns and abstractions for reuse (Refactor)",
      "id": "Patterns and abstractions for reuse (Refactor)",
      "title": "Patterns and abstractions for reuse (Refactor)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **Listing of Code Smells** is achieved through static code analysis tools such as Sonar and Kiuwan; It is in these where you can see the list issued. This practice seeks that the code always contains the best practices, making it clean and encouraging the refactoring that comes to place, to achieve said clean code.",
      "key": "List of code smells (clean code and Refactoring)",
      "id": "List of code smells (clean code and Refactoring)",
      "title": "List of code smells (clean code and Refactoring)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **Maximum Size of Classes and Functions​** is a clean coding practice that encourages the creation of classes and functions with clearly defined responsibilities, of clear scope, and that do not lead to excessive and unnecessarily long code in lines of code. You can see the complete guideline on [Tamaño máximo de Clases y Funciones](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7406/Tamaño-Clases-y-Funciones)",
      "key": "Maximum size of classes and functions",
      "id": "Maximum size of classes and functions",
      "title": "Maximum size of classes and functions",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **Maximum Cyclomatic Complexity** is a calculation that consists of determining how many variants in the execution flow exist in a program. The number that this analysis yields is the value of the Cyclomatic Complexity itself. The Maximum Cyclomatic Complexity recommended in Bancolombia is 7, and it can be extended, solidly arguing why, up to 10. Beyond that, it is not tolerable. SonarQube is the tool that is currently in charge of automatically controlling compliance with this practice. You can see the complete guideline on [Maximum Cyclomatic Complexity.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7522/Complejidad-Ciclomática)",
      "key": "Maximum Cyclomatic Complexity",
      "id": "Maximum Cyclomatic Complexity",
      "title": "Maximum Cyclomatic Complexity",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **SOLID principles** are one of the fundamental guidelines in modern Software Engineering. These seek that the software be designed and implemented with five basic principles: Single responsibility principle, Open/Close principle, Liskov substitution principle, Interface Segregation principle and Dependency Inversion principle. You can find out more about them at [guideline on SOLID principles.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/8240/Principios-SOLID)",
      "key": "SOLID Principles / Dependency Inversion / Dependency Injection",
      "id": "SOLID Principles / Dependency Inversion / Dependency Injection",
      "title": "SOLID Principles / Dependency Inversion / Dependency Injection",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Constant code reviews ** is a practice that seeks to consolidate the code review culture leveraged on tools that streamline the process and encourage the use of controls in Control Systems tools of versions. Bancolombia has features in Azure DevOps to carry out this practice. You can see the complete guideline on [Constant code reviews​](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7894/Constant-Code-Reviews%E2%80%8B)",
      "key": "Constant code reviews",
      "id": "Constant code reviews",
      "title": "Constant code reviews",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**Test-Driven Development (TDD)** is based on formalizing a piece of functionality as a test, implementing the functionality such that the test passes, and iterating the process. Test-Driven Development (TDD) is a technique for building software that guides software development by writing tests. It was developed by Kent Beck in the late 1990\\'s as part of Extreme Programming. In essence you follow three simple steps repeatedly: Write a test for the next bit of functionality you want to add; Write the functional code until the test passes; and Refactor both new and old code to make it well structured. \\nKnow more [here](https://martinfowler.com/bliki/TestDrivenDevelopment.html)",
      "key": "Test driven development",
      "id": "Test driven development",
      "title": "Test driven development",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The practice of **Fitness Functions** seeks the implementation of manual or automatic processes that help ensure that developments retain the most relevant non-functional characteristics. these can be owned by the development team or they can be owned by a more transversal component that watches over the different practices in the solutions. You can see the complete guideline on [Fitness Functions](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/10910/Fitness-Functions)",
      "key": "Architectural Fitness Functions",
      "id": "Architectural Fitness Functions",
      "title": "Architectural Fitness Functions",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "A Bounded Context is a conceptual boundary that materializes in a software artifact: the microservice. Finding them is an interdisciplinary and objective process through which conceptual and logical limits are identified that clearly show the grouping of common functionalities. It seeks to narrow down the total scope of an application somewhat, modeling the responsibilities of the components, through a rigorous process of identifying common functionalities that make it possible to establish a logical limit of responsibilities. See the guideline on [Bounded contexts as Microservices.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/13194/Bounded-contexts-como-Microservicios?anchor=bounded-contexts-como-microservicios)",
      "key": "Bounded context as microservices",
      "id": "Bounded context as microservices",
      "title": "Bounded context as microservices",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "With **Domain contexts instead of Layered Silos** we seek a different approach when thinking about the organization, an approach that seeks to find and define the different layers by business models rather than defining silos or pre-defined layers. established in the organization. \\nThis practice is closely linked to the practice of Event First Domain Driven Design because this practice seeks to solidify the emphasis on events, how to define them , use them, model them, contextualize the implications and differences with a traditional model, leading us to event-oriented systems.\\n You can see below the guideline on [Domain contexts instead of Layered Silos](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/12436/Event-First-Domain-driven-Design-(DDD))",
      "key": "Domain contexts instead of Layered Silos",
      "id": "Domain contexts instead of Layered Silos",
      "title": "Domain contexts instead of Layered Silos",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The comparison **Message Orientation vs Synchronous Service Orientation** seeks to elucidate the types of interaction that can occur between distributed systems, which is normally governed by two forms of communication: synchronous communications and asynchronous communications. These are represented in practice in two concepts that are very much in use today and almost in opposition: Message-driven services vs. Synchronic services. \\nTaking this into account when designing the application is key, as it will determine the consistency and robustness of our application. For this we are going to review conceptual considerations to take into account, not only in relation to implementation, but especially in the design section.\\n You can see below the guideline on [Message Orientation vs Synchronous Service Orientation](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/13192/Orientación-a-Mensajes-vs-Orientación-a-servicios-síncronos)",
      "key": "Message Orientation vs Synchronous Services Orientation",
      "id": "Message Orientation vs Synchronous Services Orientation",
      "title": "Message Orientation vs Synchronous Services Orientation",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "DDD Strategic Design Mapping from business architecture (Context Map) focuses on understanding and identifying the different bounded contexts and their ubiquitous language, which are related to the problem being modeled and seeks to group and classify them in subdomains: core, support and generic. In addition, it aims to identify the types of relationships between the bounded contexts to understand the dynamics of the domain.\\n You can see below the guidance on: [Mapping of the DDD Strategic Design from the business architecture (Context Map).](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnolog%C3%ADa/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnolog%C3%ADa.wiki/12436/Event-First-Domain-driven-Design-(DDD)?anchor=**domain-driven-design-estrat%C3%A9gico**#**domain-driven-design-estrat%C3%A9gico**)",
      "key": "Mapping of the DDD Strategic Design from the business architecture (Context Map)",
      "id": "Mapping of the DDD Strategic Design from the business architecture (Context Map)",
      "title": "Mapping of the DDD Strategic Design from the business architecture (Context Map)",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **License compliance** is of the utmost importance in open source and since Bancolombia has open source projects, it is necessary to clarify the matter. This practice seeks to make it completely clear what can and cannot be done with the open source software provided by us to developers external to Grupo Bancolombia. In addition, it aims to make clear the terms of use of the type of license under which a certain software component released as open source is. You can see the guideline on [Licence Compliance.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7371/Licencias)",
      "key": "Licence compliance",
      "id": "Licence compliance",
      "title": "Licence compliance",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "**The Evaluation Criteria for the use of Open source** is a practice that gives important guidelines when considering the use of a library, framework or open source code is the license it has associated. Improperly choosing to use code under a specific license may have legal implications for the organization. You can see the complete guideline on [Evaluation criteria for the use of Open source](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7371/Licencias)",
      "key": "Evaluation criteria for the use​ of Open source",
      "id": "Evaluation criteria for the use​ of Open source",
      "title": "Evaluation criteria for the use​ of Open source",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The **Government of the adequate contribution** seeks to make it completely clear what can and cannot be done with the open source software provided by us to developers external to Grupo Bancolombia. In addition, it intends to make clear the terms of use of the type of license under which a certain software component released as open source is.\\n You can see below the guideline on [Evaluation criteria for the use of Open Source.](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7371/Licencias)",
      "key": "Governance of the adequate contribution",
      "id": "Governance of the adequate contribution",
      "title": "Governance of the adequate contribution",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Is a framework for building efficient, scalable Node.js server-side applications. It uses progressive JavaScript, is built with and fully supports TypeScript (yet still enables developers to code in pure JavaScript) and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming)",
      "key": "NestJs",
      "id": "NestJs",
      "title": "NestJs",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The practice of **Code Style ** aims to provide a set of conventions that allow unifying the style used for coding, increasing the readability, maintainability and extensibility of the code. The style of the code is related to the appearance of the code, coding with a suitable style increases readability, helps to detect errors and decreases the amount of effort in studying the code when it needs to be refactored. You can see the complete guideline on [Code Style](https://dev.azure.com/GrupoBancolombia/Vicepresidencia%20Servicios%20de%20Tecnología/_wiki/wikis/Vicepresidencia%20Servicios%20de%20Tecnología.wiki/7750/Code-Style)",
      "key": "Code Style",
      "id": "Code Style",
      "title": "Code Style",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon Polly is a service that converts text into realistic speech, allowing you to create applications that speak and entirely new categories of products with this capability. You can find more information [here�](https://aws.amazon.com/es/polly/)",
      "key": "Polly",
      "id": "Polly",
      "title": "Polly",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Amazon EMR is the industry\\'s leading cloud big data platform for processing large volumes of data using open source tools such as Apache Spark, Apache Hive, Apache HBase, Apache Flink, Apache Hudi, and Presto. you can find more information [here�](https://aws.amazon.com/es/emr/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc)",
      "key": "Amazon EMR",
      "id": "Amazon EMR",
      "title": "Amazon EMR",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "JUnit is a set of classes that allows the execution of Java classes in a controlled manner, in order to be able to evaluate if the operation of each of the methods of the class behaves as expected.",
      "key": "Junit",
      "id": "Junit",
      "title": "Junit",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "The [pytest framework](https://docs.pytest.org/en/6.2.x/) makes it easy to write small tests   yet scales to support complex functional testing for applications and libraries.",
      "key": "Pytest",
      "id": "Pytest",
      "title": "Pytest",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "Unit testing framework for Elixir.",
      "key": "ExUnit",
      "id": "ExUnit",
      "title": "ExUnit",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "[Karate](https://github.com/intuit/karate) is the only open-source tool to combine API test-automation mocks  performance-testing and even UI automation into a single  unified framework. The BDD syntax popularized by Cucumber is language-neutral\t and easy for even non-programmers. Assertions and HTML reports are built-in  and you can run tests in parallel for speed.\\nThere\\'s also a cross-platform stand-alone executable for teams not comfortable with Java. You don\\'t have to compile code. Just write tests in a simple  readable syntax - carefully designed for HTTP,  JSON,  GraphQL and XML. And you can mix API and UI test-automation within the same test script.",
      "key": "Karate Framework",
      "id": "Karate Framework",
      "title": "Karate Framework",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "[Playwright](https://playwright.dev/docs/intro/) is a Node.js library to automate Chromium  Firefox and WebKit with a single API. Playwright is built to enable cross-browser web automation that is **ever-green capable reliable** and **fast**.",
      "key": "Playwright",
      "id": "Playwright",
      "title": "Playwright",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "[Citrus](https://citrusframework.org) is a test framework written in Java that is able to create fully automated end-to-end use case tests for enterprise SOA applications. Citrus simulates surrounding interface partners supporting a huge set of different transports and protocols like Http, JMS, TCP/IP, FTP, SOAP, XML and JSON.",
      "key": "Citrus",
      "id": "Citrus",
      "title": "Citrus",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "The [Screenplay Pattern](https://serenity-js.org/handbook/thinking-in-serenity-js/screenplay-pattern.html) is a user-centred approach to writing high-quality automated acceptance tests. It steers you towards an effective use of layers of abstraction  helps your tests capture the business vernacular  and encourages good testing and software engineering habits.\\nInstead of focusing on low-level interface-centric interactions you describe your test scenarios in a similar way you\\'d describe them to a human being - an actor in Screenplay-speak. You write simple\t readable and highly-reusable code that instructs the actors what activities to perform and what things to check. The domain-specific test language you create is used to express screenplays - the activities for the actors to perform in a given test scenario.",
      "key": "Screenplay Pattern",
      "id": "Screenplay Pattern",
      "title": "Screenplay Pattern",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "language-and-frameworks",
      "description": "[Appium](https://appium.io) is an open source test automation framework for use with native  hybrid and mobile web apps. It drives iOS Android  and Windows apps using the WebDriver protocol.",
      "key": "Appium",
      "id": "Appium",
      "title": "Appium",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "[Fluid Attacks ASM](https://fluidattacks.com/categories/asm/) can help your company understand its exposure and reduce the corresponding attack surface.",
      "key": "Attack Surface Manager",
      "id": "Attack Surface Manager",
      "title": "Attack Surface Manager",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "platforms",
      "description": "Vulnerability management tool owned by 7 Way Security",
      "key": "7wayops",
      "id": "7wayops",
      "title": "7wayops",
      "timeline": [
        {
          "moved": 0,
          "ringId": "trial",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "Shift left refers to moving security sooner in the development process.",
      "key": "Shift Left Security",
      "id": "Shift Left Security",
      "title": "Shift Left Security",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "techniques",
      "description": "DevSecOps automates the integration of security at every phase of the software development lifecycle, from initial design through integration, testing, deployment, and software delivery.",
      "key": "DevSecOps",
      "id": "DevSecOps",
      "title": "DevSecOps",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "DevSecOps Engine is a product orchestrated through pipelines with the ability to execute security checks automatically, simulating different hacking scenarios to guarantee the correct adoption of good security practices and compliance with security standards or requirements in APIs.",
      "key": "DevSecOps Engine",
      "id": "DevSecOps Engine",
      "title": "DevSecOps Engine",
      "timeline": [
        {
          "moved": 0,
          "ringId": "assess",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "The [OWASP ](https://owasp.org/www-project-top-ten/) Top 10 is a standard awareness document for developers and web application security. It represents a broad consensus about the most critical security risks to web applications.",
      "key": "OWASP",
      "id": "OWASP",
      "title": "OWASP",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    },
    {
      "quadrant": "tools",
      "description": "Hygieia from CapitalOne combines a number of DevOps tools available which improves our product delivery including Jenkins, Gitlab, TeamCity, SonarQube, Jira etc. Hygieia dashboards assist in achieving process transparency and therefore help establish feedback loops that are the underlying concept of lean and DevOps. They contain interactive elements which enable drill-down and linking to the connected tools.",
      "key": "Hygieia",
      "id": "Hygieia",
      "title": "Hygieia",
      "timeline": [
        {
          "moved": 0,
          "ringId": "adopt",
          "date": "2022-12-09"
        }
      ]
    }
  ]
}
